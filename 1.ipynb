{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a64bd86f-31c8-4def-aa95-ae516c1dfb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Saurabh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Saurabh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Saurabh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer, TweetTokenizer, RegexpTokenizer, MWETokenizer\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')     \n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29a98338-9724-4316-8520-35a9db767af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " I'm getting on Borderlands, and I will murder you all! ðŸ˜ˆ #gaming #fun @user\n"
     ]
    }
   ],
   "source": [
    "# sample tweet text\n",
    "text = \"I'm getting on Borderlands, and I will murder you all! ðŸ˜ˆ #gaming #fun @user\"\n",
    "print(\"Original Text:\\n\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "638d1d15-4c7b-4031-a796-46c5d9e6d9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whitespace Tokenization:\n",
      " [\"I'm\", 'getting', 'on', 'Borderlands,', 'and', 'I', 'will', 'murder', 'you', 'all!', 'ðŸ˜ˆ', '#gaming', '#fun', '@user']\n"
     ]
    }
   ],
   "source": [
    "# Split by whitespace\n",
    "whitespace_tokens = text.split()\n",
    "print(\"Whitespace Tokenization:\\n\", whitespace_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2878814-7ed1-4e4e-a492-ad8b3828546b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation-Based Tokenization:\n",
      " ['I', 'm', 'getting', 'on', 'Borderlands', 'and', 'I', 'will', 'murder', 'you', 'all', 'gaming', 'fun', 'user']\n"
     ]
    }
   ],
   "source": [
    "# Regex tokenizer (splits on non-word characters)\n",
    "regex_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "regex_tokens = regex_tokenizer.tokenize(text)\n",
    "print(\"Punctuation-Based Tokenization:\\n\", regex_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fa6f40b-37e3-439f-8811-0da42ed179ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treebank Tokenization:\n",
      " ['I', \"'m\", 'getting', 'on', 'Borderlands', ',', 'and', 'I', 'will', 'murder', 'you', 'all', '!', 'ðŸ˜ˆ', '#', 'gaming', '#', 'fun', '@', 'user']\n"
     ]
    }
   ],
   "source": [
    "# Treebank Tokenizer (standard for grammatical text)\n",
    "treebank_tokenizer = TreebankWordTokenizer()\n",
    "treebank_tokens = treebank_tokenizer.tokenize(text)\n",
    "print(\"Treebank Tokenization:\\n\", treebank_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9974e2b-203c-4f5c-85d9-9523a45e8d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet Tokenization:\n",
      " [\"I'm\", 'getting', 'on', 'Borderlands', ',', 'and', 'I', 'will', 'murder', 'you', 'all', '!', 'ðŸ˜ˆ', '#gaming', '#fun', '@user']\n"
     ]
    }
   ],
   "source": [
    "# Tweet Tokenizer (handles emojis, mentions, hashtags better)\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "tweet_tokens = tweet_tokenizer.tokenize(text)\n",
    "print(\"Tweet Tokenization:\\n\", tweet_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c16964d-a77b-4726-9ba7-c463fec6e19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Word Expression Tokenization:\n",
      " [\"I'm\", 'getting_on', 'Borderlands,', 'and', 'I', 'will', 'murder', 'you', 'all!', 'ðŸ˜ˆ', '#gaming', '#fun', '@user']\n"
     ]
    }
   ],
   "source": [
    "# Define some multi-word expressions\n",
    "mwe_tokenizer = MWETokenizer([('getting', 'on'), ('Borderlands', ',')])\n",
    "mwe_tokens = mwe_tokenizer.tokenize(text.split())\n",
    "print(\"Multi-Word Expression Tokenization:\\n\", mwe_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8540df2e-ceee-40fc-9d4e-d9f6a002cbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer:\n",
      " ['i', 'm', 'get', 'on', 'borderland', 'and', 'i', 'will', 'murder', 'you', 'all', 'game', 'fun', 'user']\n",
      "Snowball Stemmer:\n",
      " ['i', 'm', 'get', 'on', 'borderland', 'and', 'i', 'will', 'murder', 'you', 'all', 'game', 'fun', 'user']\n"
     ]
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "snowball = SnowballStemmer(\"english\")\n",
    "\n",
    "tokens = regex_tokens  # using regex-based clean tokens\n",
    "\n",
    "porter_stems = [porter.stem(token) for token in tokens]\n",
    "snowball_stems = [snowball.stem(token) for token in tokens]\n",
    "\n",
    "print(\"Porter Stemmer:\\n\", porter_stems)\n",
    "print(\"Snowball Stemmer:\\n\", snowball_stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef90277b-ae75-4e15-bcf9-095a4f0303f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Tokens:\n",
      " ['I', 'm', 'getting', 'on', 'Borderlands', 'and', 'I', 'will', 'murder', 'you', 'all', 'gaming', 'fun', 'user']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatization (default is noun unless specified)\n",
    "lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "print(\"Lemmatized Tokens:\\n\", lemmas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a0b3c5-09d0-4326-a3e7-960ede8fd59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d9309-84f1-4505-8775-1782f01c7c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
